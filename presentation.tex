\documentclass{beamer}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\newcommand{\del}{\nabla}
\begin{document}
\title{Extremal Optimization}
\author{Howon Lee}
\maketitle
%%what is the question?
%%why is it interesting?
%%what approach will you be taking to address it?
%%details of approach. specific target phenomenon. model network task setting, architecture, processing and learning algorithm, training environment
%%expected or preliminary results
%%problems and issues
%%summary and next steps

%%% start with the Bak-sneppen story. Model of qualitative parts of evolution. Lattice model, do some gnarly physics. Talk about the results of those people.
%%% Bak and Chialvo do adaptive extremal optimization on a fake-ish neural net model. Conjunctive model means that it just sucks for problems like the parity problem, although the forgiveness thing ties everything together.
%%% shit results on Bak net. note that the shit results are a little less worse for natural data
%%% Talk about extremal optimization in the more abstract sense. Travelling salesman problem. Boetticher's work on the deterministic EO and tau-EO.
%%% Figuring out applying the abstract EO algorithm to things. Note that the locality of fitness that the model requires is much easier to do in Boltzmann machine, decide to do RBM on those machines.
%%% Results. Try some classifications. Do time course of learning on the shit error measure that we have and a non-shit error measure. Compare to gradient descent for learning. Apologize for not having simulated annealing to compare to.

\begin{frame}

\end{frame}
\end{document}

